{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "\n",
    "from transformers import AutoImageProcessor\n",
    "from datasets import Dataset, DatasetDict, Features, Image, Sequence, Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d6414b5557b4e5c8a9622c057c161dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"Data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(data_path + \"train.csv\")\n",
    "valid_df = pd.read_csv(data_path + \"valid.csv\")\n",
    "test_df = pd.read_csv(data_path + \"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_columns = ['Crack', 'Red-Dots', 'Toothmark']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert binary-encoded features to array of labels\n",
    "def binary_to_labels(row, label_cols):\n",
    "    return [float(row[col]) for col in label_cols]\n",
    "\n",
    "for df in [train_df, valid_df, test_df]:\n",
    "    df['labels'] = df.apply(lambda row: binary_to_labels(row, label_columns), axis=1)\n",
    "    df.drop(columns=label_columns, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append image path to filename\n",
    "def add_image_path(df):\n",
    "    df['image'] = data_path + df['filename']\n",
    "    return df[['image', 'labels']]\n",
    "\n",
    "train_dataset_df = add_image_path(train_df)\n",
    "valid_dataset_df = add_image_path(valid_df)\n",
    "test_dataset_df = add_image_path(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data/CC_211_jpg.rf.31153880eb2dbd26c2a84ec2063...</td>\n",
       "      <td>[0.0, 0.0, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data/CC_1873_jpg.rf.30bd76e7beefb2ee1bb72b6c33...</td>\n",
       "      <td>[1.0, 1.0, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data/CC_1584_jpg.rf.3074bed75cb82a848747c8534c...</td>\n",
       "      <td>[0.0, 1.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data/CC_1130_jpg.rf.321c01c097f04c8f20de88d709...</td>\n",
       "      <td>[0.0, 1.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data/CC_526_jpg.rf.33619b9cdb0f9b4fd0725af2847...</td>\n",
       "      <td>[0.0, 1.0, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>741</th>\n",
       "      <td>Data/CC_162_jpg.rf.fc096c7c27c0ae53b58160ddad5...</td>\n",
       "      <td>[1.0, 0.0, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>742</th>\n",
       "      <td>Data/CC_1059_jpg.rf.fd96a222061b07c745d63ceeb7...</td>\n",
       "      <td>[1.0, 1.0, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>743</th>\n",
       "      <td>Data/CC_1035_jpg.rf.fb05385f3eb3212f397c42d36a...</td>\n",
       "      <td>[0.0, 1.0, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>744</th>\n",
       "      <td>Data/CC_1355_jpg.rf.ffb1d2f17400373be04d0afc8f...</td>\n",
       "      <td>[0.0, 1.0, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>745</th>\n",
       "      <td>Data/CC_131_jpg.rf.ff7272da2c6474e4e1cbeefe0cb...</td>\n",
       "      <td>[1.0, 1.0, 1.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>746 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 image           labels\n",
       "0    Data/CC_211_jpg.rf.31153880eb2dbd26c2a84ec2063...  [0.0, 0.0, 1.0]\n",
       "1    Data/CC_1873_jpg.rf.30bd76e7beefb2ee1bb72b6c33...  [1.0, 1.0, 1.0]\n",
       "2    Data/CC_1584_jpg.rf.3074bed75cb82a848747c8534c...  [0.0, 1.0, 0.0]\n",
       "3    Data/CC_1130_jpg.rf.321c01c097f04c8f20de88d709...  [0.0, 1.0, 0.0]\n",
       "4    Data/CC_526_jpg.rf.33619b9cdb0f9b4fd0725af2847...  [0.0, 1.0, 1.0]\n",
       "..                                                 ...              ...\n",
       "741  Data/CC_162_jpg.rf.fc096c7c27c0ae53b58160ddad5...  [1.0, 0.0, 1.0]\n",
       "742  Data/CC_1059_jpg.rf.fd96a222061b07c745d63ceeb7...  [1.0, 1.0, 1.0]\n",
       "743  Data/CC_1035_jpg.rf.fb05385f3eb3212f397c42d36a...  [0.0, 1.0, 1.0]\n",
       "744  Data/CC_1355_jpg.rf.ffb1d2f17400373be04d0afc8f...  [0.0, 1.0, 1.0]\n",
       "745  Data/CC_131_jpg.rf.ff7272da2c6474e4e1cbeefe0cb...  [1.0, 1.0, 1.0]\n",
       "\n",
       "[746 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 3\n",
    "class_names = ['Crack', 'Red-Dots', 'Toothmark']\n",
    "\n",
    "# Labels is an array of floats\n",
    "features = Features({\n",
    "    'image': Image(),\n",
    "    'labels': Sequence(feature=Value('float32'), length=num_classes)\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train labels example: image     Data/CC_211_jpg.rf.31153880eb2dbd26c2a84ec2063...\n",
      "labels                                      [0.0, 0.0, 1.0]\n",
      "Name: 0, dtype: object\n",
      "Validation labels example: image     Data/CC_1930_jpg.rf.c3eed44b2a8b24b72f69fc19ba...\n",
      "labels                                      [1.0, 1.0, 1.0]\n",
      "Name: 0, dtype: object\n",
      "Test labels example: image     Data/CC_1401_jpg.rf.10a517516c5386991c4133e502...\n",
      "labels                                      [0.0, 1.0, 0.0]\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(\"Train labels example:\", train_dataset_df.iloc[0])\n",
    "print(\"Validation labels example:\", valid_dataset_df.iloc[0])\n",
    "print(\"Test labels example:\", test_dataset_df.iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Dataset.from_pandas(train_dataset_df, features=features, preserve_index=False)\n",
    "valid_dataset = Dataset.from_pandas(valid_dataset_df, features=features, preserve_index=False)\n",
    "test_dataset = Dataset.from_pandas(test_dataset_df, features=features, preserve_index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_dict = DatasetDict({\n",
    "    'train': train_dataset,\n",
    "    'validation': valid_dataset,\n",
    "    'test': test_dataset\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['image', 'labels'],\n",
       "        num_rows: 746\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['image', 'labels'],\n",
       "        num_rows: 214\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['image', 'labels'],\n",
       "        num_rows: 106\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fast image processor class <class 'transformers.models.vit.image_processing_vit_fast.ViTImageProcessorFast'> is available for this model. Using slow image processor class. To use the fast image processor class set `use_fast=True`.\n"
     ]
    }
   ],
   "source": [
    "# Modify depending on model\n",
    "image_processor = AutoImageProcessor.from_pretrained(\"google/vit-base-patch16-384\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    images = image_processor(examples['image'], return_tensors='pt')\n",
    "    labels = torch.tensor(examples['labels'], dtype=torch.float)\n",
    "    \n",
    "    return {\n",
    "        'pixel_values': images['pixel_values'],\n",
    "        'labels': labels\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4b1b1ffec4340e6a90f5a8fb80bf4ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/746 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28783ff721bb4e81ab56481ebb9a189a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/214 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7350f88a120e4356881defae8408dba9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/106 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset_dict = dataset_dict.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "350c427dbc504ccf9ade91d5ee4ed769",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "176f7b45c5a349f3a8f75dc4fb97b36c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/249 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12439b66712948209b16ee21895b75cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/3 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f3a9faedb42427191f73197644eaf7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/249 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f58b21ec24a4ad9b1ec8c5d6cd1e88b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/3 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e29e12571c348d0ae3ef23fe82c0ca2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/248 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e39747d30b60490597ff3c2fcf707341",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/3 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e426d9fc59ec41298f711777a80ee052",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0475a9787b8743e7928327a312540586",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/214 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f2ba1efba6f4fad836dda1e82565f2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/3 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5020c8915fa54b8482f1043853ab3bac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Uploading the dataset shards:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9587884fc80d4ba3b9109cf296cb91ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/106 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f94d21c93d24d3791453afc583e3300",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Creating parquet from Arrow format:   0%|          | 0/2 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/e1010101/tongue-images-384-no-augmentation/commit/5fdf03fe4958f3027cc87abce34f0712ecdafc99', commit_message='Upload dataset', commit_description='', oid='5fdf03fe4958f3027cc87abce34f0712ecdafc99', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_dict.push_to_hub(\"e1010101/tongue-images-384-no-augmentation\", private=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Standard",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
